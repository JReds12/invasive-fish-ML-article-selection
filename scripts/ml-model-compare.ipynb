{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jredi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, roc_curve, accuracy_score\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Journal Name</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Pages</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>categories</th>\n",
       "      <th>TitleAbstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aldridge, C. A., and E. C. Boone</td>\n",
       "      <td>2022</td>\n",
       "      <td>Simple models to quickly estimate the probable...</td>\n",
       "      <td>River Research and Applications</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>1154-1166</td>\n",
       "      <td>Species distribution models provide biologists...</td>\n",
       "      <td>1</td>\n",
       "      <td>simpl model quick estim probabl rang datalimit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Banan, A., A. Nasiri, and A. Taheri-Garavand</td>\n",
       "      <td>2020</td>\n",
       "      <td>Deep learning-based appearance features extrac...</td>\n",
       "      <td>Aquacultural Engineering</td>\n",
       "      <td>89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fish species identification is vital for aquac...</td>\n",
       "      <td>1</td>\n",
       "      <td>deep learningbas appear featur extract autom c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barnes, M. A., W. L. Chadderton, C. L. Jerde, ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Environmental conditions influence edna partic...</td>\n",
       "      <td>Environmental DNA</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>643-653</td>\n",
       "      <td>Knowledge about the size of environmental DNA ...</td>\n",
       "      <td>1</td>\n",
       "      <td>environment condit influenc edna particl size ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Behera, B. K., A. K. Bera, P. Paria, A. Das, P...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Identification and pathogenicity of plesiomona...</td>\n",
       "      <td>Aquaculture</td>\n",
       "      <td>493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314-318</td>\n",
       "      <td>Plesiomonas shigelloides was isolated from dis...</td>\n",
       "      <td>1</td>\n",
       "      <td>identif pathogen plesiomona shigelloid silver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Borland, L. K., C. J. Mulcahy, B. A. Bennie, D...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Using markov chains to quantitatively assess m...</td>\n",
       "      <td>Natural Resource Modeling</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natural resource managers use barriers to dete...</td>\n",
       "      <td>1</td>\n",
       "      <td>use markov chain quantit assess movement patte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Author  Year  \\\n",
       "0                   Aldridge, C. A., and E. C. Boone  2022   \n",
       "1       Banan, A., A. Nasiri, and A. Taheri-Garavand  2020   \n",
       "2  Barnes, M. A., W. L. Chadderton, C. L. Jerde, ...  2021   \n",
       "3  Behera, B. K., A. K. Bera, P. Paria, A. Das, P...  2018   \n",
       "4  Borland, L. K., C. J. Mulcahy, B. A. Bennie, D...  2020   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Simple models to quickly estimate the probable...   \n",
       "1  Deep learning-based appearance features extrac...   \n",
       "2  Environmental conditions influence edna partic...   \n",
       "3  Identification and pathogenicity of plesiomona...   \n",
       "4  Using markov chains to quantitatively assess m...   \n",
       "\n",
       "                      Journal Name Volume Issue      Pages  \\\n",
       "0  River Research and Applications     38     6  1154-1166   \n",
       "1         Aquacultural Engineering     89   NaN        NaN   \n",
       "2                Environmental DNA      3     3    643-653   \n",
       "3                      Aquaculture    493   NaN    314-318   \n",
       "4        Natural Resource Modeling     33     4        NaN   \n",
       "\n",
       "                                            Abstract  categories  \\\n",
       "0  Species distribution models provide biologists...           1   \n",
       "1  Fish species identification is vital for aquac...           1   \n",
       "2  Knowledge about the size of environmental DNA ...           1   \n",
       "3  Plesiomonas shigelloides was isolated from dis...           1   \n",
       "4  Natural resource managers use barriers to dete...           1   \n",
       "\n",
       "                                       TitleAbstract  \n",
       "0  simpl model quick estim probabl rang datalimit...  \n",
       "1  deep learningbas appear featur extract autom c...  \n",
       "2  environment condit influenc edna particl size ...  \n",
       "3  identif pathogen plesiomona shigelloid silver ...  \n",
       "4  use markov chain quantit assess movement patte...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "df = pd.read_csv(r'..\\data\\processed\\train-test.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label encoder \n",
    "label_encoder = LabelEncoder()\n",
    "df[\"categories\"] = label_encoder.fit_transform(df['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "\n",
    "# Removal of HTML tags and whitespace\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Get the set of English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to remove HTML tags\n",
    "def basic_clean(text):\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Function to remove stopwords from text\n",
    "    def remove_stopwords(text):\n",
    "        # Tokenize the text\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        # Filter out stopwords\n",
    "        filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "        # Reconstruct the text without stopwords\n",
    "        text_without_stopwords = ' '.join(filtered_tokens)\n",
    "        return text_without_stopwords\n",
    "\n",
    "    text = remove_stopwords(text)\n",
    "\n",
    "    stemmer = SnowballStemmer(language = 'english')\n",
    "    text = \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "    return text\n",
    "    \n",
    "df_clean['TitleAbstract'] = df_clean['TitleAbstract'].apply(basic_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "categories\n",
       "0    408\n",
       "1    233\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[\"categories\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y\n",
    "X = df_clean['TitleAbstract']\n",
    "y = df_clean['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Imbalanced data set - since we consistently saw more irrevlant document, it would be better to train model on imbalanced data set\n",
    "\n",
    "# # Create X and y\n",
    "# sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# for train_index, test_index in sss.split(X, y):\n",
    "#     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing Dataset: \n",
    "I want to prioritize the reduction of false negatives when selecting relevant articles. I decided to balance dataset to give mode a better chance of learning to detect relevant articles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create balanced datasets for article selection\n",
    "balanced_dfs = []\n",
    "\n",
    "# Count the number of rows in each category\n",
    "category_counts = df['categories'].value_counts()\n",
    "\n",
    "# Find the minority category\n",
    "minority_category = category_counts.idxmin()\n",
    "\n",
    "# Get the size of the minority category\n",
    "minority_category_size = category_counts[minority_category]\n",
    "\n",
    "# Sample rows from the majority category to match the size of the minority category\n",
    "majority_category_rows = df[df['categories'] != minority_category]\n",
    "balanced_majority_category_rows = majority_category_rows.sample(n=minority_category_size, random_state=42)\n",
    "\n",
    "# Get the minority category rows\n",
    "minority_category_rows = df[df['categories'] == minority_category]\n",
    "\n",
    "# Concatenate the minority and balanced majority category rows\n",
    "balanced_df = pd.concat([minority_category_rows, balanced_majority_category_rows])\n",
    "\n",
    "balanced_dfs.append(balanced_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(balanced_df['TitleAbstract'], balanced_df['categories'], test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec model\n",
    "sentences = [text.split() for text in X]\n",
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Custom vectorizers\n",
    "class Word2VecVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        def get_word2vec_vector(text):\n",
    "            words = text.split()\n",
    "            vectors = [self.model.wv[word] for word in words if word in self.model.wv]\n",
    "            if vectors:\n",
    "                return np.mean(vectors, axis=0)\n",
    "            else:\n",
    "                return np.zeros(self.model.vector_size)\n",
    "        \n",
    "        return np.array([get_word2vec_vector(text) for text in X])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vectorizers\n",
    "vectorizers = {\n",
    "    \"CountVectorizer\": CountVectorizer(),\n",
    "    \"TFIDFVectorizer\": TfidfVectorizer(),\n",
    "    \"HashingVectorizer\": HashingVectorizer(n_features=2**10),\n",
    "    \"Word2VecVectorizer\": Word2VecVectorizer(word2vec_model)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "models = {\n",
    "    \"LR\": (LogisticRegression(), {\n",
    "        'model__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "        'model__C': [0.1, 1, 10, 100],\n",
    "        'model__solver': ['liblinear', 'lbfgs', 'saga'],\n",
    "        'model__multi_class': ['ovr', 'multinomial'],\n",
    "    }),\n",
    "    \"kNN\": (KNeighborsClassifier(), {\n",
    "        'model__n_neighbors': list(range(1, 21)),\n",
    "        'model__weights': ['uniform', 'distance'],\n",
    "        'model__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    }),\n",
    "    \"SVM\": (SVC(), {\n",
    "        'model__C': [0.1, 1, 10, 100],\n",
    "        'model__gamma': [1, 0.1, 0.01, 0.001],\n",
    "        'model__kernel': ['linear', 'rbf', 'sigmoid'] # decided not to test 'poly'\n",
    "    }),\n",
    "    \"Random Forest\": (RandomForestClassifier(), {\n",
    "        'model__n_estimators': [50, 100, 200],\n",
    "        'model__max_depth': [None, 10, 20],\n",
    "        'model__min_samples_split': [2, 5]\n",
    "    }),\n",
    "    \"Decision Tree\": (DecisionTreeClassifier(), {\n",
    "        'model__max_depth': [None, 2, 4, 6, 8],\n",
    "        'model__min_samples_split': [2, 5, 10]\n",
    "    }),\n",
    "    \"Naive Bayes\": (MultinomialNB(), {\n",
    "        'model__alpha': [0.1, 0.5, 1.0, 1.5, 2.0]\n",
    "    })\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping HashingVectorizer with Naive Bayes due to incompatible values.\n",
      "Skipping Word2VecVectorizer with Naive Bayes due to incompatible values.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 21\u001b[0m\n\u001b[0;32m     15\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m     16\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvectorizer\u001b[39m\u001b[38;5;124m'\u001b[39m, vectorizer),\n\u001b[0;32m     17\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, model)\n\u001b[0;32m     18\u001b[0m ])\n\u001b[0;32m     20\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, params, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, scoring \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m     22\u001b[0m best_models[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvec_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_  \u001b[38;5;66;03m# Store the best model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m best_accuracy \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_score_\n",
      "File \u001b[1;32mc:\\Users\\jredi\\Documents\\coding\\invasive-fish-ML-article-selection\\venvSelectArticle\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jredi\\Documents\\coding\\invasive-fish-ML-article-selection\\venvSelectArticle\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:968\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    962\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    963\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 968\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    972\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jredi\\Documents\\coding\\invasive-fish-ML-article-selection\\venvSelectArticle\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1543\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1543\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jredi\\Documents\\coding\\invasive-fish-ML-article-selection\\venvSelectArticle\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:914\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    909\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    910\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    911\u001b[0m         )\n\u001b[0;32m    912\u001b[0m     )\n\u001b[1;32m--> 914\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    934\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    935\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jredi\\Documents\\coding\\invasive-fish-ML-article-selection\\venvSelectArticle\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jredi\\Documents\\coding\\invasive-fish-ML-article-selection\\venvSelectArticle\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\jredi\\Documents\\coding\\invasive-fish-ML-article-selection\\venvSelectArticle\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\jredi\\Documents\\coding\\invasive-fish-ML-article-selection\\venvSelectArticle\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jredi\\Documents\\coding\\invasive-fish-ML-article-selection\\venvSelectArticle\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:910\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    907\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    909\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m--> 910\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_params_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\n\u001b[0;32m    912\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    913\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "File \u001b[1;32mc:\\Users\\jredi\\Documents\\coding\\invasive-fish-ML-article-selection\\venvSelectArticle\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:971\u001b[0m, in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, score_params, error_score)\u001b[0m\n\u001b[0;32m    969\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscore_params)\n\u001b[0;32m    970\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 971\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mscore_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[0;32m    975\u001b[0m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jredi\\Documents\\coding\\invasive-fish-ML-article-selection\\venvSelectArticle\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:279\u001b[0m, in \u001b[0;36m_BaseScorer.__call__\u001b[1;34m(self, estimator, X, y_true, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m     _kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_cached_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jredi\\Documents\\coding\\invasive-fish-ML-article-selection\\venvSelectArticle\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:371\u001b[0m, in \u001b[0;36m_Scorer._score\u001b[1;34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[0m\n\u001b[0;32m    369\u001b[0m pos_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m is_regressor(estimator) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_pos_label()\n\u001b[0;32m    370\u001b[0m response_method \u001b[38;5;241m=\u001b[39m _check_response_method(estimator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_method)\n\u001b[1;32m--> 371\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmethod_caller\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    375\u001b[0m scoring_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sign \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score_func(y_true, y_pred, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscoring_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\jredi\\Documents\\coding\\invasive-fish-ML-article-selection\\venvSelectArticle\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:89\u001b[0m, in \u001b[0;36m_cached_call\u001b[1;34m(cache, estimator, response_method, *args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response_method \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[response_method]\n\u001b[1;32m---> 89\u001b[0m result, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_get_response_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     cache[response_method] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32mc:\\Users\\jredi\\Documents\\coding\\invasive-fish-ML-article-selection\\venvSelectArticle\\Lib\\site-packages\\sklearn\\utils\\_response.py:211\u001b[0m, in \u001b[0;36m_get_response_values\u001b[1;34m(estimator, X, response_method, pos_label, return_response_method_used)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m target_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    209\u001b[0m         pos_label \u001b[38;5;241m=\u001b[39m classes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 211\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mprediction_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_log_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    214\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m _process_predict_proba(\n\u001b[0;32m    215\u001b[0m         y_pred\u001b[38;5;241m=\u001b[39my_pred,\n\u001b[0;32m    216\u001b[0m         target_type\u001b[38;5;241m=\u001b[39mtarget_type,\n\u001b[0;32m    217\u001b[0m         classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[0;32m    218\u001b[0m         pos_label\u001b[38;5;241m=\u001b[39mpos_label,\n\u001b[0;32m    219\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jredi\\Documents\\coding\\invasive-fish-ML-article-selection\\venvSelectArticle\\Lib\\site-packages\\sklearn\\pipeline.py:603\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 603\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    606\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jredi\\Documents\\coding\\invasive-fish-ML-article-selection\\venvSelectArticle\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "Cell \u001b[1;32mIn[40], line 41\u001b[0m, in \u001b[0;36mDoc2VecVectorizer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_doc2vec_vector\u001b[39m(text):\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39minfer_vector(text\u001b[38;5;241m.\u001b[39msplit())\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mget_doc2vec_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m X])\n",
      "Cell \u001b[1;32mIn[40], line 39\u001b[0m, in \u001b[0;36mDoc2VecVectorizer.transform.<locals>.get_doc2vec_vector\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_doc2vec_vector\u001b[39m(text):\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jredi\\Documents\\coding\\invasive-fish-ML-article-selection\\venvSelectArticle\\Lib\\site-packages\\gensim\\models\\doc2vec.py:651\u001b[0m, in \u001b[0;36mDoc2Vec.infer_vector\u001b[1;34m(self, doc_words, alpha, min_alpha, epochs)\u001b[0m\n\u001b[0;32m    646\u001b[0m         train_document_dm_concat(\n\u001b[0;32m    647\u001b[0m             \u001b[38;5;28mself\u001b[39m, doc_words, doctag_indexes, alpha, work, neu1,\n\u001b[0;32m    648\u001b[0m             learn_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, learn_hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, doctag_vectors\u001b[38;5;241m=\u001b[39mdoctag_vectors, doctags_lockf\u001b[38;5;241m=\u001b[39mdoctags_lockf\n\u001b[0;32m    649\u001b[0m         )\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 651\u001b[0m         \u001b[43mtrain_document_dm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoctag_indexes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneu1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlearn_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn_hidden\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoctag_vectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoctag_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoctags_lockf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoctags_lockf\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    655\u001b[0m     alpha \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m alpha_delta\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doctag_vectors[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to hold the best models\n",
    "best_models = {}\n",
    "\n",
    "# Grid Search for each vectorizer and model\n",
    "for vec_name, vectorizer in vectorizers.items():\n",
    "    for name, (model, params) in models.items():\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "\n",
    "            # Skip MultinomialNB with HashingVectorizer\n",
    "            if name == \"Naive Bayes\" and vec_name in [\"HashingVectorizer\", \"Word2VecVectorizer\"]:\n",
    "                print(f\"Skipping {vec_name} with {name} due to incompatible values.\")\n",
    "                continue\n",
    "\n",
    "            pipeline = Pipeline([\n",
    "                ('vectorizer', vectorizer),\n",
    "                ('model', model)\n",
    "            ])\n",
    "            \n",
    "            grid_search = GridSearchCV(pipeline, params, cv = 10, scoring = 'recall')\n",
    "            grid_search.fit(X_train, y_train)  # Fit the model\n",
    "            best_models[f\"{vec_name}_{name}\"] = grid_search.best_estimator_  # Store the best model\n",
    "            best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CountVectorizer_LR': Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                 ('model',\n",
       "                  LogisticRegression(C=1, multi_class='ovr',\n",
       "                                     solver='liblinear'))]),\n",
       " 'CountVectorizer_kNN': Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                 ('model', KNeighborsClassifier(n_neighbors=11))]),\n",
       " 'CountVectorizer_SVM': Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                 ('model', SVC(C=0.1, gamma=0.01, kernel='sigmoid'))]),\n",
       " 'CountVectorizer_Random Forest': Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                 ('model',\n",
       "                  RandomForestClassifier(max_depth=20, min_samples_split=5,\n",
       "                                         n_estimators=50))]),\n",
       " 'CountVectorizer_Decision Tree': Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                 ('model', DecisionTreeClassifier(max_depth=2))]),\n",
       " 'CountVectorizer_Naive Bayes': Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                 ('model', MultinomialNB(alpha=2.0))]),\n",
       " 'TFIDFVectorizer_LR': Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                 ('model',\n",
       "                  LogisticRegression(C=1, multi_class='ovr',\n",
       "                                     solver='liblinear'))]),\n",
       " 'TFIDFVectorizer_kNN': Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                 ('model', KNeighborsClassifier(n_neighbors=19))]),\n",
       " 'TFIDFVectorizer_SVM': Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                 ('model', SVC(C=1, gamma=1, kernel='sigmoid'))]),\n",
       " 'TFIDFVectorizer_Random Forest': Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                 ('model', RandomForestClassifier(min_samples_split=5))]),\n",
       " 'TFIDFVectorizer_Decision Tree': Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                 ('model',\n",
       "                  DecisionTreeClassifier(max_depth=4, min_samples_split=5))]),\n",
       " 'TFIDFVectorizer_Naive Bayes': Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                 ('model', MultinomialNB(alpha=2.0))]),\n",
       " 'HashingVectorizer_LR': Pipeline(steps=[('vectorizer', HashingVectorizer(n_features=1024)),\n",
       "                 ('model',\n",
       "                  LogisticRegression(C=0.1, multi_class='ovr',\n",
       "                                     solver='liblinear'))]),\n",
       " 'HashingVectorizer_kNN': Pipeline(steps=[('vectorizer', HashingVectorizer(n_features=1024)),\n",
       "                 ('model', KNeighborsClassifier(n_neighbors=19))]),\n",
       " 'HashingVectorizer_SVM': Pipeline(steps=[('vectorizer', HashingVectorizer(n_features=1024)),\n",
       "                 ('model', SVC(C=1, gamma=0.1))]),\n",
       " 'HashingVectorizer_Random Forest': Pipeline(steps=[('vectorizer', HashingVectorizer(n_features=1024)),\n",
       "                 ('model',\n",
       "                  RandomForestClassifier(max_depth=20, min_samples_split=5))]),\n",
       " 'HashingVectorizer_Decision Tree': Pipeline(steps=[('vectorizer', HashingVectorizer(n_features=1024)),\n",
       "                 ('model', DecisionTreeClassifier(max_depth=2))]),\n",
       " 'Word2VecVectorizer_LR': Pipeline(steps=[('vectorizer',\n",
       "                  Word2VecVectorizer(model=<gensim.models.word2vec.Word2Vec object at 0x0000012833F67B60>)),\n",
       "                 ('model',\n",
       "                  LogisticRegression(C=100, multi_class='ovr', penalty='l1',\n",
       "                                     solver='liblinear'))]),\n",
       " 'Word2VecVectorizer_kNN': Pipeline(steps=[('vectorizer',\n",
       "                  Word2VecVectorizer(model=<gensim.models.word2vec.Word2Vec object at 0x0000012834164DA0>)),\n",
       "                 ('model', KNeighborsClassifier(n_neighbors=7))]),\n",
       " 'Word2VecVectorizer_SVM': Pipeline(steps=[('vectorizer',\n",
       "                  Word2VecVectorizer(model=<gensim.models.word2vec.Word2Vec object at 0x0000012833FA91F0>)),\n",
       "                 ('model', SVC(C=100, gamma=0.1))]),\n",
       " 'Word2VecVectorizer_Random Forest': Pipeline(steps=[('vectorizer',\n",
       "                  Word2VecVectorizer(model=<gensim.models.word2vec.Word2Vec object at 0x0000012834058170>)),\n",
       "                 ('model', RandomForestClassifier(max_depth=10))]),\n",
       " 'Word2VecVectorizer_Decision Tree': Pipeline(steps=[('vectorizer',\n",
       "                  Word2VecVectorizer(model=<gensim.models.word2vec.Word2Vec object at 0x0000012834232AB0>)),\n",
       "                 ('model', DecisionTreeClassifier(max_depth=2))]),\n",
       " 'Doc2VecVectorizer_LR': Pipeline(steps=[('vectorizer',\n",
       "                  Doc2VecVectorizer(model=<gensim.models.doc2vec.Doc2Vec object at 0x0000012832C34BF0>)),\n",
       "                 ('model',\n",
       "                  LogisticRegression(C=0.1, multi_class='ovr', penalty='l1',\n",
       "                                     solver='saga'))]),\n",
       " 'Doc2VecVectorizer_kNN': Pipeline(steps=[('vectorizer',\n",
       "                  Doc2VecVectorizer(model=<gensim.models.doc2vec.Doc2Vec object at 0x000001283415C740>)),\n",
       "                 ('model', KNeighborsClassifier(n_neighbors=19))])}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Model  Accuracy  Precision    Recall        F1\n",
      "0                 CountVectorizer_LR  0.744681   0.745586  0.744681  0.744796\n",
      "1                CountVectorizer_kNN  0.521277   0.511847  0.521277  0.406375\n",
      "2                CountVectorizer_SVM  0.691489   0.696258  0.691489  0.687325\n",
      "3      CountVectorizer_Random Forest  0.723404   0.726029  0.723404  0.723404\n",
      "4      CountVectorizer_Decision Tree  0.489362   0.511184  0.489362  0.414060\n",
      "5        CountVectorizer_Naive Bayes  0.744681   0.759140  0.744681  0.738967\n",
      "6                 TFIDFVectorizer_LR  0.776596   0.776518  0.776596  0.776469\n",
      "7                TFIDFVectorizer_kNN  0.712766   0.718544  0.712766  0.708888\n",
      "8                TFIDFVectorizer_SVM  0.765957   0.766016  0.765957  0.765638\n",
      "9      TFIDFVectorizer_Random Forest  0.734043   0.735520  0.734043  0.732676\n",
      "10     TFIDFVectorizer_Decision Tree  0.574468   0.574722  0.574468  0.564946\n",
      "11       TFIDFVectorizer_Naive Bayes  0.734043   0.788830  0.734043  0.717038\n",
      "12              HashingVectorizer_LR  0.702128   0.703854  0.702128  0.700082\n",
      "13             HashingVectorizer_kNN  0.638298   0.641492  0.638298  0.632437\n",
      "14             HashingVectorizer_SVM  0.702128   0.713035  0.702128  0.695462\n",
      "15   HashingVectorizer_Random Forest  0.670213   0.670008  0.670213  0.669425\n",
      "16   HashingVectorizer_Decision Tree  0.638298   0.637890  0.638298  0.637805\n",
      "17             Word2VecVectorizer_LR  0.723404   0.723307  0.723404  0.723027\n",
      "18            Word2VecVectorizer_kNN  0.680851   0.683321  0.680851  0.680851\n",
      "19            Word2VecVectorizer_SVM  0.680851   0.689983  0.680851  0.673709\n",
      "20  Word2VecVectorizer_Random Forest  0.648936   0.654528  0.648936  0.648101\n",
      "21  Word2VecVectorizer_Decision Tree  0.606383   0.647536  0.606383  0.564547\n",
      "22              Doc2VecVectorizer_LR  0.680851   0.683918  0.680851  0.677326\n",
      "23             Doc2VecVectorizer_kNN  0.712766   0.727126  0.712766  0.705339\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best models on the test set\n",
    "metrics_list = []\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    # Extract the vectorizer and the classifier from the pipeline\n",
    "    vectorizer = model.named_steps['vectorizer']\n",
    "    classifier = model.named_steps['model']\n",
    "    \n",
    "    # Transform the test data\n",
    "    X_test_vec = vectorizer.transform(X_test)  # Transform X_test with the same vectorizer used in training\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test_vec)\n",
    "    \n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Store metrics\n",
    "    metrics = [name, accuracy, precision, recall, f1]\n",
    "    metrics_list.append(metrics)\n",
    "    \n",
    "# Create a DataFrame with the results\n",
    "column_names = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1']\n",
    "result_df = pd.DataFrame(metrics_list, columns=column_names)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
      "                ('model',\n",
      "                 LogisticRegression(C=1, multi_class='ovr',\n",
      "                                    solver='liblinear'))])\n"
     ]
    }
   ],
   "source": [
    "# Export best model\n",
    "max_index = result_df['Recall'].idxmax()\n",
    "best_model = best_models.get(result_df.loc[max_index,'Model'])\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "with open('../models/ml_model.pkl', 'wb') as file:\n",
    "    pickle.dump((best_model, vectorizer), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvSelectArticle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
